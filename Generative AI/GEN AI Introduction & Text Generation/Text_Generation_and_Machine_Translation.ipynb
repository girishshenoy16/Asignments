{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrP0jYxEfFBj"
      },
      "source": [
        "## Text Generation and Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) What is Generative AI and what are its primary use cases across industries?\n",
        "\n",
        "->\n",
        "\n",
        "Generative AI refers to a class of artificial intelligence models that are capable of creating new content such as text, images, audio, video, or code, rather than just analyzing or classifying existing data. These models learn the underlying patterns and structure of data and use that knowledge to generate realistic and meaningful outputs.\n",
        "\n",
        " Primary Use Cases Across Industries\n",
        "- Healthcare\n",
        "  - Generating synthetic medical data\n",
        "  - Assisting in medical report summarization\n",
        "  - Drug discovery and molecular design\n",
        "- Finance\n",
        "  - Automated report generation\n",
        "  - Fraud scenario simulation\n",
        "  - Personalized financial advice\n",
        "- Entertainment & Media\n",
        "  - Storytelling, poetry, and script writing\n",
        "  - Music and image generation\n",
        "  - Game design and character creation\n",
        "- Education\n",
        "  - Automated content creation\n",
        "  - Personalized learning material\n",
        "  - Intelligent tutoring systems\n",
        "- Software Development\n",
        "  - Code generation and debugging\n",
        "  - Documentation writing\n",
        "  - Test case generation\n",
        "\n",
        "Overall, Generative AI enhances creativity, productivity, and automation across domains.\n",
        "\n",
        "\n",
        " 2) Explain the role of probabilistic modeling in generative models. How do these models differ from discriminative models?\n",
        "\n",
        "->\n",
        "\n",
        "Probabilistic modeling plays a central role in generative models by learning the joint probability distribution of data and labels.\n",
        "\n",
        " Role of Probabilistic Modeling\n",
        "- Models uncertainty in data\n",
        "- Enables sampling of new data points\n",
        "- Allows generation of diverse and realistic outputs\n",
        "- Helps capture hidden (latent) structures in data\n",
        "\n",
        "Generative models learn:\n",
        "\\[\n",
        "P(X, Y) \\quad \\text{or} \\quad P(X)\n",
        "\\]\n",
        "where \\(X\\) represents the data.\n",
        "\n",
        "\n",
        " Difference Between Generative and Discriminative Models\n",
        "\n",
        "| Aspect | Generative Models | Discriminative Models |\n",
        "|------|------------------|-----------------------|\n",
        "| What they learn | Joint distribution \\(P(X, Y)\\) | Conditional probability \\(P(Y|X)\\) |\n",
        "| Goal | Generate new data | Predict labels |\n",
        "| Output | New samples | Class predictions |\n",
        "| Examples | GANs, VAEs, HMMs | Logistic Regression, SVM, CNNs |\n",
        "\n",
        "In simple terms:  \n",
        "Generative models learn *how data is created*, while discriminative models learn *how to distinguish between classes*.\n",
        "\n",
        "\n",
        " 3) What is the difference between Autoencoders and Variational Autoencoders (VAEs) in the context of text generation?\n",
        "\n",
        "->\n",
        "\n",
        " Autoencoders\n",
        "- Consist of an encoder and a decoder\n",
        "- Learn a deterministic compressed representation of input data\n",
        "- Focus on reconstruction accuracy\n",
        "- Not ideal for generating diverse new text\n",
        "\n",
        " Variational Autoencoders (VAEs)\n",
        "- Learn a probabilistic latent space\n",
        "- Encoder outputs a distribution (mean and variance)\n",
        "- Decoder samples from this distribution\n",
        "- Better suited for text generation and creativity\n",
        "\n",
        " Key Differences\n",
        "\n",
        "| Aspect | Autoencoder | Variational Autoencoder |\n",
        "|------|-------------|-------------------------|\n",
        "| Latent space | Deterministic | Probabilistic |\n",
        "| Output diversity | Low | High |\n",
        "| Sampling | Not supported | Supported |\n",
        "| Text generation | Limited | Effective |\n",
        "\n",
        "VAEs enable smooth interpolation and generation of novel text samples, making them more suitable for generative tasks.\n",
        "\n",
        "\n",
        " 4) Describe the working of attention mechanisms in Neural Machine Translation (NMT). Why are they critical?\n",
        "\n",
        "->\n",
        "\n",
        "In Neural Machine Translation, attention mechanisms allow the model to focus on relevant parts of the input sentence when generating each word in the output sentence.\n",
        "\n",
        " How Attention Works\n",
        "1. The encoder processes the entire source sentence.\n",
        "2. At each decoding step, attention:\n",
        "   - Assigns weights to all input tokens\n",
        "   - Determines which source words are most relevant\n",
        "3. The decoder uses this weighted information to generate the next word.\n",
        "\n",
        "This avoids compressing the entire sentence into a single fixed-length vector.\n",
        "\n",
        " Why Attention Is Critical\n",
        "- Handles long sentences effectively\n",
        "- Improves translation accuracy\n",
        "- Aligns source and target words dynamically\n",
        "- Enables context-aware translations\n",
        "\n",
        "Attention mechanisms are the foundation of Transformer models, which outperform traditional RNN-based NMT systems.\n",
        "\n",
        "\n",
        " 5) What ethical considerations must be addressed when using generative AI for creative content such as poetry or storytelling?\n",
        "\n",
        "->\n",
        "\n",
        "Using Generative AI for creative content raises important ethical concerns.\n",
        "\n",
        " Key Ethical Considerations\n",
        "- Originality and Plagiarism\n",
        "  - Risk of generating content too similar to existing works\n",
        "- Copyright and Ownership\n",
        "  - Unclear ownership of AI-generated content\n",
        "- Bias and Representation\n",
        "  - Models may reflect societal biases present in training data\n",
        "- Misinformation\n",
        "  - Generated stories may spread false or misleading narratives\n",
        "- Human Creativity\n",
        "  - Over-reliance on AI may devalue human creative effort\n",
        "- Transparency\n",
        "  - Users should know whether content is AI-generated\n",
        "\n",
        " Responsible Use\n",
        "- Clear disclosure of AI involvement\n",
        "- Human oversight in creative workflows\n",
        "- Ethical dataset curation\n",
        "- Respect for cultural and artistic values"
      ],
      "metadata": {
        "id": "j_CqvK0ml_Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch --quiet\n",
        "!pip install tensorflow --quiet"
      ],
      "metadata": {
        "id": "gTDetr5ZhGM_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "6) Use the following small text dataset to train a simple Variational\n",
        "Autoencoder (VAE) for text reconstruction:\n",
        "\n",
        "[\"The sky is blue\", \"The sun is bright\", \"The grass is green\",\n",
        "\"The night is dark\", \"The stars are shining\"]\n",
        "\n",
        "1. Preprocess the data (tokenize and pad the sequences).\n",
        "2. Build a basic VAE model for text reconstruction.\n",
        "3. Train the model and show how it reconstructs or generates similar sentences.\n",
        "\n",
        "Include your code, explanation, and sample outputs.\n",
        "\n",
        "->\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Embedding, LSTM, Dense,\n",
        "    RepeatVector, Layer\n",
        ")\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "texts = [\n",
        "    \"The sky is blue\",\n",
        "    \"The sun is bright\",\n",
        "    \"The grass is green\",\n",
        "    \"The night is dark\",\n",
        "    \"The stars are shining\"\n",
        "]\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "print(\"Word Index:\", word_index)\n",
        "print(\"Padded Sequences:\\n\", padded_sequences)\n",
        "\n",
        "\n",
        "class Sampling(Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "class KLDivergenceLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        kl_loss = -0.5 * tf.reduce_mean(\n",
        "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        )\n",
        "        self.add_loss(kl_loss)\n",
        "        return inputs\n",
        "\n",
        "\n",
        "embedding_dim = 16\n",
        "latent_dim = 8\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_len,))\n",
        "x = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
        "x = LSTM(32)(x)\n",
        "\n",
        "z_mean = Dense(latent_dim)(x)\n",
        "z_log_var = Dense(latent_dim)(x)\n",
        "\n",
        "# KL loss (safe)\n",
        "z_mean, z_log_var = KLDivergenceLayer()([z_mean, z_log_var])\n",
        "\n",
        "# Sampling\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = RepeatVector(max_len)(z)\n",
        "decoder_lstm = LSTM(32, return_sequences=True)(decoder_inputs)\n",
        "decoder_outputs = Dense(vocab_size, activation=\"softmax\")(decoder_lstm)\n",
        "\n",
        "vae = Model(encoder_inputs, decoder_outputs)\n",
        "\n",
        "\n",
        "vae.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\"\n",
        ")\n",
        "\n",
        "vae.summary()\n",
        "\n",
        "vae.fit(\n",
        "    padded_sequences,\n",
        "    padded_sequences,\n",
        "    epochs=200,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"✅ VAE training completed\")\n",
        "\n",
        "\n",
        "predictions = vae.predict(padded_sequences)\n",
        "\n",
        "reverse_word_index = {i: w for w, i in word_index.items()}\n",
        "\n",
        "def decode_sentence(pred):\n",
        "    words = []\n",
        "    for token in pred:\n",
        "        word = reverse_word_index.get(np.argmax(token), \"\")\n",
        "        if word:\n",
        "            words.append(word)\n",
        "    return \" \".join(words)\n",
        "\n",
        "print(\"\\nOriginal vs Reconstructed Sentences:\\n\")\n",
        "for i, pred in enumerate(predictions):\n",
        "    print(\"Original     :\", texts[i])\n",
        "    print(\"Reconstructed:\", decode_sentence(pred))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tz8e8PrBRRkO",
        "outputId": "4d43ae9f-96cc-42c6-976f-854c09921a90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Index: {'the': 1, 'is': 2, 'sky': 3, 'blue': 4, 'sun': 5, 'bright': 6, 'grass': 7, 'green': 8, 'night': 9, 'dark': 10, 'stars': 11, 'are': 12, 'shining': 13}\n",
            "Padded Sequences:\n",
            " [[ 1  3  2  4]\n",
            " [ 1  5  2  6]\n",
            " [ 1  7  2  8]\n",
            " [ 1  9  2 10]\n",
            " [ 1 11 12 13]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m224\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m6,272\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m264\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m264\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ kl_divergence_layer │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m),       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mKLDivergenceLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)]        │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sampling (\u001b[38;5;33mSampling\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ kl_divergence_la… │\n",
              "│                     │                   │            │ kl_divergence_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ sampling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m5,248\u001b[0m │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │        \u001b[38;5;34m462\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,272</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ kl_divergence_layer │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>),       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">KLDivergenceLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)]        │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sampling</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ kl_divergence_la… │\n",
              "│                     │                   │            │ kl_divergence_la… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sampling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,734\u001b[0m (49.74 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,734</span> (49.74 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,734\u001b[0m (49.74 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,734</span> (49.74 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ VAE training completed\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step\n",
            "\n",
            "Original vs Reconstructed Sentences:\n",
            "\n",
            "Original     : The sky is blue\n",
            "Reconstructed: the is is is\n",
            "\n",
            "Original     : The sun is bright\n",
            "Reconstructed: the is is is\n",
            "\n",
            "Original     : The grass is green\n",
            "Reconstructed: is is is is\n",
            "\n",
            "Original     : The night is dark\n",
            "Reconstructed: is is is is\n",
            "\n",
            "Original     : The stars are shining\n",
            "Reconstructed: the shining shining shining\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vKYRM7camlV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "68da111fe7184dcf92716556617f7ca4",
            "7f37a9b490b747e3bdb918d87912811e",
            "0235d195408547aeb0df4e2f5b7f6dc9",
            "f32f94a66a3e4cf1ad9cd82f060ed962",
            "453b3292196c4656a18c46343679e49d",
            "299c78b06c2f4a79bee75841c16f79a1",
            "bbe436b6a134439dbdada18114b2e0cd",
            "601682b0c9a54b1a85cb5d02f3229b24",
            "6480e4aba3d84345801ab14a465b7b6a",
            "c6ae7531c3e74b5c8771ab0e1d357657",
            "293337012c81445fa6aec8572796435d"
          ]
        },
        "outputId": "6961752b-a5e3-4799-de92-d0236eee14d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68da111fe7184dcf92716556617f7ca4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Translation:\n",
            " Translate the following text from English to French:\n",
            "English: Artificial intelligence is transforming industries by enabling machines to learn from data and make intelligent decisions.\n",
            "French: The future of artificial intelligence will be a world of machines. Artificial Intelligence is the future. The world is changing. We are changing the world. It is time to change the way we think. This is a new era of technology. A new age of innovation. And it is not just about the machines, it's about us. Our future is about machines and machines are the only way to make it happen.\n",
            "German Translation:\n",
            " Translate the following text from English to German:\n",
            "English: Artificial intelligence is transforming industries by enabling machines to learn from data and make intelligent decisions.\n",
            "German: The future of artificial intelligence will be a world of machines. Artificial Intelligence is the future. The world is changing. It is a new world. We are changing the world, and we are transforming it. This is what we call the Artificial Human. In this world we will have machines that are smarter than humans. They will learn and learn. And they will do it in a way that is not human. That is why we have\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "7)  Use a pre-trained GPT model (like GPT-2 or GPT-3) to translate a short\n",
        "English paragraph into French and German. Provide the original and translated text.\n",
        "->\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "\n",
        "english_text = (\n",
        "    \"Artificial intelligence is transforming industries by enabling machines \"\n",
        "    \"to learn from data and make intelligent decisions.\"\n",
        ")\n",
        "\n",
        "\n",
        "# Translate English to French\n",
        "\n",
        "prompt_french = f\"Translate the following text from English to French:\\nEnglish: {english_text}\\nFrench:\"\n",
        "\n",
        "inputs_fr = tokenizer.encode(prompt_french, return_tensors=\"pt\")\n",
        "outputs_fr = model.generate(\n",
        "    inputs_fr,\n",
        "    max_length=120,\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "french_translation = tokenizer.decode(outputs_fr[0], skip_special_tokens=True)\n",
        "print(\"French Translation:\\n\", french_translation)\n",
        "\n",
        "\n",
        "# Translate English to German\n",
        "\n",
        "prompt_german = f\"Translate the following text from English to German:\\nEnglish: {english_text}\\nGerman:\"\n",
        "\n",
        "inputs_de = tokenizer.encode(prompt_german, return_tensors=\"pt\")\n",
        "outputs_de = model.generate(\n",
        "    inputs_de,\n",
        "    max_length=120,\n",
        "    num_return_sequences=1,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "german_translation = tokenizer.decode(outputs_de[0], skip_special_tokens=True)\n",
        "print(\"German Translation:\\n\", german_translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "6MbiezoHmsjw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "outputId": "87adb044-621b-4d4f-d34d-e66e753bbdf6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m704\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m640\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m),   │     \u001b[38;5;34m33,024\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m),   │     \u001b[38;5;34m33,024\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ additive_attention  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m64\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mAdditiveAttention\u001b[0m) │                   │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ additive_attenti… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │      \u001b[38;5;34m1,290\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ additive_attention  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AdditiveAttention</span>) │                   │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ additive_attenti… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,746\u001b[0m (268.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,746</span> (268.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,746\u001b[0m (268.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,746</span> (268.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed\n",
            "English : i love you\n",
            "Spanish : amo amo\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "8) Implement a simple attention-based encoder-decoder model for\n",
        "English-to-Spanish translation using Tensorflow or PyTorch.\n",
        "\n",
        "->\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# English sentences\n",
        "eng_sentences = [\n",
        "    \"i love you\",\n",
        "    \"how are you\",\n",
        "    \"i am happy\",\n",
        "    \"good morning\",\n",
        "    \"thank you\"\n",
        "]\n",
        "\n",
        "# Spanish translations\n",
        "spa_sentences = [\n",
        "    \"te amo\",\n",
        "    \"como estas\",\n",
        "    \"estoy feliz\",\n",
        "    \"buenos dias\",\n",
        "    \"gracias\"\n",
        "]\n",
        "\n",
        "# Tokenizers\n",
        "eng_tokenizer = Tokenizer()\n",
        "spa_tokenizer = Tokenizer()\n",
        "\n",
        "eng_tokenizer.fit_on_texts(eng_sentences)\n",
        "spa_tokenizer.fit_on_texts(spa_sentences)\n",
        "\n",
        "eng_seq = eng_tokenizer.texts_to_sequences(eng_sentences)\n",
        "spa_seq = spa_tokenizer.texts_to_sequences(spa_sentences)\n",
        "\n",
        "# Padding\n",
        "max_eng_len = max(len(seq) for seq in eng_seq)\n",
        "max_spa_len = max(len(seq) for seq in spa_seq)\n",
        "\n",
        "eng_pad = pad_sequences(eng_seq, maxlen=max_eng_len, padding='post')\n",
        "spa_pad = pad_sequences(spa_seq, maxlen=max_spa_len, padding='post')\n",
        "\n",
        "eng_vocab = len(eng_tokenizer.word_index) + 1\n",
        "spa_vocab = len(spa_tokenizer.word_index) + 1\n",
        "\n",
        "embedding_dim = 64\n",
        "units = 64\n",
        "\n",
        "encoder_inputs = tf.keras.Input(shape=(max_eng_len,))\n",
        "encoder_embedding = Embedding(eng_vocab, embedding_dim)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(\n",
        "    units, return_sequences=True, return_state=True\n",
        ")(encoder_embedding)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "\n",
        "decoder_inputs = tf.keras.Input(shape=(max_spa_len,))\n",
        "decoder_embedding = Embedding(spa_vocab, embedding_dim)(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "    decoder_embedding, initial_state=encoder_states\n",
        ")\n",
        "\n",
        "# Apply attention\n",
        "context_vector = attention([decoder_outputs, encoder_outputs])\n",
        "\n",
        "# Concatenate attention context and decoder output\n",
        "decoder_concat = tf.keras.layers.Concatenate()(\n",
        "    [decoder_outputs, context_vector]\n",
        ")\n",
        "\n",
        "decoder_dense = Dense(spa_vocab, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat)\n",
        "\n",
        "\n",
        "model = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs],\n",
        "    decoder_outputs\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "spa_pad_input = spa_pad[:, :-1]\n",
        "spa_pad_output = spa_pad[:, 1:]\n",
        "\n",
        "model.fit(\n",
        "    [eng_pad, spa_pad_input],\n",
        "    spa_pad_output,\n",
        "    epochs=300,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"Training completed\")\n",
        "\n",
        "def translate(sentence):\n",
        "    seq = eng_tokenizer.texts_to_sequences([sentence])\n",
        "    seq = pad_sequences(seq, maxlen=max_eng_len, padding='post')\n",
        "\n",
        "    start_token = spa_tokenizer.word_index.get(\"te\", 1)\n",
        "    decoder_input = np.zeros((1, max_spa_len))\n",
        "    decoder_input[0, 0] = start_token\n",
        "\n",
        "    prediction = model.predict([seq, decoder_input], verbose=0)\n",
        "    tokens = np.argmax(prediction[0], axis=1)\n",
        "\n",
        "    reverse_spa_index = {i: w for w, i in spa_tokenizer.word_index.items()}\n",
        "    return \" \".join([reverse_spa_index.get(t, \"\") for t in tokens])\n",
        "\n",
        "print(\"English :\", \"i love you\")\n",
        "print(\"Spanish :\", translate(\"i love you\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "9)  Use the following short poetry dataset to simulate poem generation with a pre-trained GPT model:\n",
        "\n",
        "[\"Roses are red, violets are blue,\",\n",
        "\"Sugar is sweet, and so are you.\",\n",
        "\"The moon glows bright in silent skies,\",\n",
        "\"A bird sings where the soft wind sighs.\"]\n",
        "\n",
        "Using this dataset as a reference for poetic structure and language, generate a new 2-4\n",
        "line poem using a pre-trained GPT model (such as GPT-2). You may simulate\n",
        "fine-tuning by prompting the model with similar poetic patterns.\n",
        "\n",
        "Include your code, the prompt used, and the generated poem in your answer.\n",
        "\n",
        "->\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load GPT-2 tokenizer and model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "prompt = (\n",
        "    \"Roses are red, violets are blue,\\n\"\n",
        "    \"Sugar is sweet, and so are you.\\n\"\n",
        "    \"The moon glows bright in silent skies,\\n\"\n",
        "    \"A bird sings where the soft wind sighs.\\n\\n\"\n",
        "    \"Write a short poem:\\n\"\n",
        ")\n",
        "\n",
        "inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(\n",
        "    inputs,\n",
        "    max_length=120,\n",
        "    num_return_sequences=1,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "OVHIfAZRklEA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "c8cdc09c6df945c2a7845162420f10fc",
            "72399b58673b48a494e932bc677a238e",
            "f3d4661f73004f18a5034cb792bfb1cb",
            "1ed6e597db654fd3bbabe0e94d51c4f3",
            "d72bcf0ed17c4357bc5f93f8e1ca33fe",
            "5613b948ed19453585982a1b12bbeea2",
            "701d14bff86a410f977aec48cceb8d80",
            "390056cc8f44418d8048a2558140d001",
            "3d72569c86ee4f4b967d6801b534ea55",
            "0bce132aa05c41289be5a889133f1c84",
            "346acf772f9c4ab59d414039d7e02465"
          ]
        },
        "outputId": "5f1068ab-4467-4e78-9036-76744699991c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8cdc09c6df945c2a7845162420f10fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
            "Key                  | Status     |  | \n",
            "---------------------+------------+--+-\n",
            "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roses are red, violets are blue,\n",
            "Sugar is sweet, and so are you.\n",
            "The moon glows bright in silent skies,\n",
            "A bird sings where the soft wind sighs.\n",
            "\n",
            "Write a short poem:\n",
            "\"I am the moon, the sun, my soul, I am your soul.\"\n",
            ". . .\n",
            "I'm the star, your star. I'm your sun. You're my star\n",
            "And I'll be your moon. And I will be yours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) Imagine you are building a creative writing assistant for a publishing company. The assistant should generate story plots and character descriptions using Generative AI. Describe how you would design the system, including model selection, training data, bias mitigation, and evaluation methods. Explain the real-world challenges you might face.\n",
        "\n",
        "->\n",
        "\n",
        "Imagine building a creative writing assistant for a publishing company that helps authors generate story plots and character descriptions. Such a system must balance creativity with quality, originality, and ethical responsibility.\n",
        "\n",
        "System Design Overview\n",
        "\n",
        "The creative writing assistant can be designed as a text-generation system powered by Generative AI, consisting of the following components:\n",
        "\n",
        "1. User Input Interface\n",
        "2. Generative Model Core\n",
        "3. Post-processing & Safety Layer\n",
        "4. Evaluation & Feedback Module\n",
        "\n",
        "Model Selection\n",
        "\n",
        "The choice of model is critical for generating coherent and creative text.\n",
        "\n",
        "- Transformer-based Language Models (preferred):\n",
        "  - Examples: GPT-style models, T5, or similar large language models\n",
        "  - Strengths:\n",
        "    - Strong contextual understanding\n",
        "    - Ability to generate long, coherent narratives\n",
        "    - Effective handling of character consistency and plot flow\n",
        "\n",
        "- Why not simpler models (RNN/LSTM)?\n",
        "  - Limited long-range coherence\n",
        "  - Struggle with complex narrative structures\n",
        "\n",
        "The model can be fine-tuned specifically for fiction writing tasks such as plot generation, dialogue creation, and character profiling.\n",
        "\n",
        "\n",
        "Training Data\n",
        "\n",
        "High-quality and diverse training data is essential.\n",
        "\n",
        "Sources of Training Data\n",
        "- Public-domain novels and short stories\n",
        "- Story summaries and plot outlines\n",
        "- Character descriptions from fiction databases\n",
        "- Screenplays and scripts (where legally permitted)\n",
        "\n",
        "Data Preparation\n",
        "- Clean and normalize text\n",
        "- Remove duplicates and copyrighted material\n",
        "- Annotate structure (e.g., plot, setting, character traits)\n",
        "- Balance genres (fantasy, mystery, romance, sci-fi)\n",
        "\n",
        "Bias Mitigation Strategies\n",
        "\n",
        "Bias in generative writing can negatively impact inclusivity and representation.\n",
        "\n",
        "Mitigation Techniques\n",
        "- Use diverse and balanced datasets\n",
        "- Filter or reweight biased content during training\n",
        "- Apply debiasing techniques in embeddings\n",
        "- Include human-in-the-loop review for sensitive outputs\n",
        "- Regular audits for stereotypes related to gender, race, or culture\n",
        "\n",
        "Bias mitigation ensures fair, inclusive, and responsible creative output.\n",
        "\n",
        "\n",
        "\n",
        "Evaluation Methods\n",
        "\n",
        "Evaluating creative text is challenging and requires both automatic and human-centered approaches.\n",
        "\n",
        "Automatic Evaluation\n",
        "- Perplexity (fluency measure)\n",
        "- Diversity metrics (n-gram diversity)\n",
        "- Repetition detection\n",
        "- Length and coherence checks\n",
        "\n",
        "Human Evaluation\n",
        "- Editorial review by writers and editors\n",
        "- Creativity and originality scoring\n",
        "- Consistency of characters and plot\n",
        "- Reader engagement feedback\n",
        "\n",
        "Human evaluation is especially important for creative tasks.\n",
        "\n",
        "\n",
        "Real-World Challenges\n",
        "\n",
        "Building such a system involves several practical challenges:\n",
        "\n",
        "- Creativity vs. Originality\n",
        "  - Avoiding plagiarism while still producing engaging content\n",
        "- Copyright and Ownership\n",
        "  - Determining who owns AI-generated stories\n",
        "- Quality Control\n",
        "  - Ensuring outputs meet publishing standards\n",
        "- Bias and Cultural Sensitivity\n",
        "  - Preventing harmful stereotypes or misrepresentation\n",
        "- Over-Reliance on AI\n",
        "  - Risk of reducing human creativity and authorial voice\n",
        "- Scalability\n",
        "  - Serving multiple authors with personalized styles"
      ],
      "metadata": {
        "id": "uxUiJs11ykTM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "68da111fe7184dcf92716556617f7ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f37a9b490b747e3bdb918d87912811e",
              "IPY_MODEL_0235d195408547aeb0df4e2f5b7f6dc9",
              "IPY_MODEL_f32f94a66a3e4cf1ad9cd82f060ed962"
            ],
            "layout": "IPY_MODEL_453b3292196c4656a18c46343679e49d"
          }
        },
        "7f37a9b490b747e3bdb918d87912811e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_299c78b06c2f4a79bee75841c16f79a1",
            "placeholder": "​",
            "style": "IPY_MODEL_bbe436b6a134439dbdada18114b2e0cd",
            "value": "Loading weights: 100%"
          }
        },
        "0235d195408547aeb0df4e2f5b7f6dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601682b0c9a54b1a85cb5d02f3229b24",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6480e4aba3d84345801ab14a465b7b6a",
            "value": 148
          }
        },
        "f32f94a66a3e4cf1ad9cd82f060ed962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ae7531c3e74b5c8771ab0e1d357657",
            "placeholder": "​",
            "style": "IPY_MODEL_293337012c81445fa6aec8572796435d",
            "value": " 148/148 [00:00&lt;00:00, 269.96it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "453b3292196c4656a18c46343679e49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299c78b06c2f4a79bee75841c16f79a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbe436b6a134439dbdada18114b2e0cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "601682b0c9a54b1a85cb5d02f3229b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6480e4aba3d84345801ab14a465b7b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6ae7531c3e74b5c8771ab0e1d357657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293337012c81445fa6aec8572796435d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8cdc09c6df945c2a7845162420f10fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72399b58673b48a494e932bc677a238e",
              "IPY_MODEL_f3d4661f73004f18a5034cb792bfb1cb",
              "IPY_MODEL_1ed6e597db654fd3bbabe0e94d51c4f3"
            ],
            "layout": "IPY_MODEL_d72bcf0ed17c4357bc5f93f8e1ca33fe"
          }
        },
        "72399b58673b48a494e932bc677a238e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5613b948ed19453585982a1b12bbeea2",
            "placeholder": "​",
            "style": "IPY_MODEL_701d14bff86a410f977aec48cceb8d80",
            "value": "Loading weights: 100%"
          }
        },
        "f3d4661f73004f18a5034cb792bfb1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390056cc8f44418d8048a2558140d001",
            "max": 148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d72569c86ee4f4b967d6801b534ea55",
            "value": 148
          }
        },
        "1ed6e597db654fd3bbabe0e94d51c4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bce132aa05c41289be5a889133f1c84",
            "placeholder": "​",
            "style": "IPY_MODEL_346acf772f9c4ab59d414039d7e02465",
            "value": " 148/148 [00:00&lt;00:00, 487.85it/s, Materializing param=transformer.wte.weight]"
          }
        },
        "d72bcf0ed17c4357bc5f93f8e1ca33fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5613b948ed19453585982a1b12bbeea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "701d14bff86a410f977aec48cceb8d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "390056cc8f44418d8048a2558140d001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d72569c86ee4f4b967d6801b534ea55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bce132aa05c41289be5a889133f1c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "346acf772f9c4ab59d414039d7e02465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}